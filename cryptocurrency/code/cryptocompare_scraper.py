#
# Script to pull/store cryptocurrency data from cryptocompare.com.
#
# Author: C. Bonfield
# Last Modified: 12/2017

# Import statements
import json
import requests
import datetime
import numpy as np
import pandas as pd

def clean_data(df):
    """
    Make data pulled from API neater. As written, this function simply averages
    closing prices for each cryptocurrency across the five exchanges that I've
    chosen to use.

    Inputs:
        df: data from API (straight from CSV saved after double loop below)

    Returns:
        new_df: cleaned DF (only average closing prices for each cryptocurrency)
    """
    # Drop garbage, reset index.
    df.drop(df.columns[0], axis=1, inplace=True)
    df.set_index('time', inplace=True)

    # Select only relevant columns.
    sub_df = df[['close','exchange','fsym_tsym']]

    # Treat missing values.
    sub_df.replace(0.0, np.nan, inplace=True)

    # Average over exchanges for a given closing price.
    group_df = sub_df.groupby([sub_df.index,'fsym_tsym']).agg({'close':['mean']})

    # Unstack hierarchical index, drop a few label levels.
    new_df = group_df.unstack(level='fsym_tsym')
    new_df.columns = new_df.columns.droplevel()
    new_df.columns = new_df.columns.droplevel()

    return new_df

def construct_url(params):
    """
    Build the URL associated with the call to the cryptocompare.com API.

    Input:
        params: (same as documented below in pull_data)

    Returns:
        url: URL for query
        sym_string: cryptocurrency identifier (just a label for later)
        exchange: (self-explanatory - also a label for later)
    """
    base_url = 'https://min-api.cryptocompare.com/data/histohour?'
    fsym, tsym = params['syms']
    agg = params['aggregate']
    lim = params['limit']
    exchange = params['exchange']

    ext_url = 'fsym=' + fsym + '&tsym=' + tsym + '&limit=' + lim + '&aggregate=' \
              + agg + '&e=' + exchange

    url = base_url + ext_url
    sym_string = fsym + '_' + tsym

    return url, sym_string, exchange

def dateparse(epoch_time):
    """
    Convert from epoch to human date (UTC).
    """
    return datetime.datetime.fromtimestamp(float(epoch_time))

def pull_data(params):
    """
    Call API using url generated by construct_url, add a few additional
    columns as labels.

    Inputs:
        params: parameters to pass in the query
            fsym: 'from' symbol (probably the cryptocurrency symbol)
            tsym: 'to' symbol (likely USD)
            limit: number of time points to return (max: 2000)
            e: exchange (Coinbase, Poloniex, etc. - refer to API documentation
               for an exhaustive list)

    Returns:
        data: data frame containing data from API call
    """

    url, s, e = construct_url(params)

    response = requests.get(url)
    response.raise_for_status()         # Raise exception if invalid response.
    json_response = response.json()

    data = pd.DataFrame(json_response['Data'])
    data['fsym_tsym'] = s
    data['exchange'] = e

    return data

# MAIN BODY OF CODE: For every exchange and symbol pair, scrape data via API.
#
exchanges = ['COINBASE', 'POLONIEX', 'KRAKEN', 'BITSTAMP', 'BITFINEX']
sym_pairs = [('BTC','USD'),('ETH','USD'), ('LTC','USD'), ('DASH','USD'),
             ('XMR','USD')]

full_df = pd.DataFrame() # initialize empty data frame
for sp in sym_pairs:
    for exc in exchanges:
        request_dict = {'syms': sp, 'aggregate': '1', 'limit':'2000',
                        'exchange': exc}
        df = pull_data(request_dict)

        if full_df.empty:
            full_df = df
        else:
            full_df = pd.concat([full_df, df], axis=0)

# TEST CODE (uncomment if necessary)
#
#full_df.to_csv('crypto_data_all.csv')
#test = {'syms': ('BTC','USD'), 'aggregate': '1', 'limit':'2000',
#        'exchange': 'CCCAGG'}
#y = pull_data(test)

# CLEANING CODE (uncomment if you want to do a bit of simplifying - modify the
# function clean_data above to suit your needs)
#
#test = pd.read_csv('crypto_data_all.csv', parse_dates=['time'],
#                   date_parser=dateparse)
#x = clean_data(test)
#x.to_csv('cleaned_crypto_closing_prices.csv')
